{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmFgrZXAbyaO",
        "outputId": "852a3e8f-1130-41c6-9b06-b384fe8c930f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n",
            "reduced train/val size: 50000 2000 input shape: (32, 32, 3)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 15, 15, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 256)         295168    \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 7, 7, 256)         590080    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 3, 3, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              2305000   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1000)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                10010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,275,906\n",
            "Trainable params: 3,275,906\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "391/391 [==============================] - 26s 36ms/step - loss: 2.1618 - accuracy: 0.1936 - val_loss: 1.9966 - val_accuracy: 0.3020\n",
            "Epoch 2/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.8868 - accuracy: 0.3156 - val_loss: 1.9160 - val_accuracy: 0.3040\n",
            "Epoch 3/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.7594 - accuracy: 0.3627 - val_loss: 1.7958 - val_accuracy: 0.3540\n",
            "Epoch 4/80\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.6836 - accuracy: 0.3890 - val_loss: 1.7804 - val_accuracy: 0.3680\n",
            "Epoch 5/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.6196 - accuracy: 0.4125 - val_loss: 1.6610 - val_accuracy: 0.4080\n",
            "Epoch 6/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.5677 - accuracy: 0.4311 - val_loss: 1.7175 - val_accuracy: 0.3940\n",
            "Epoch 7/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.5254 - accuracy: 0.4461 - val_loss: 1.5884 - val_accuracy: 0.4360\n",
            "Epoch 8/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.4891 - accuracy: 0.4617 - val_loss: 1.5389 - val_accuracy: 0.4575\n",
            "Epoch 9/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.4584 - accuracy: 0.4743 - val_loss: 1.4912 - val_accuracy: 0.4690\n",
            "Epoch 10/80\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.4300 - accuracy: 0.4835 - val_loss: 1.4384 - val_accuracy: 0.4915\n",
            "Epoch 11/80\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.4066 - accuracy: 0.4942 - val_loss: 1.4348 - val_accuracy: 0.4970\n",
            "Epoch 12/80\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.3842 - accuracy: 0.5037 - val_loss: 1.4091 - val_accuracy: 0.5000\n",
            "Epoch 13/80\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.3626 - accuracy: 0.5140 - val_loss: 1.4049 - val_accuracy: 0.5075\n",
            "Epoch 14/80\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.3417 - accuracy: 0.5197 - val_loss: 1.3866 - val_accuracy: 0.5185\n",
            "Epoch 15/80\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.3230 - accuracy: 0.5289 - val_loss: 1.3512 - val_accuracy: 0.5295\n",
            "Epoch 16/80\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.2994 - accuracy: 0.5412 - val_loss: 1.3228 - val_accuracy: 0.5445\n",
            "Epoch 17/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.2881 - accuracy: 0.5409 - val_loss: 1.3217 - val_accuracy: 0.5380\n",
            "Epoch 18/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.2697 - accuracy: 0.5496 - val_loss: 1.2537 - val_accuracy: 0.5590\n",
            "Epoch 19/80\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.2534 - accuracy: 0.5555 - val_loss: 1.2627 - val_accuracy: 0.5585\n",
            "Epoch 20/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.2379 - accuracy: 0.5633 - val_loss: 1.2590 - val_accuracy: 0.5665\n",
            "Epoch 21/80\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.2232 - accuracy: 0.5686 - val_loss: 1.2414 - val_accuracy: 0.5685\n",
            "Epoch 22/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.2100 - accuracy: 0.5729 - val_loss: 1.2556 - val_accuracy: 0.5630\n",
            "Epoch 23/80\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.1963 - accuracy: 0.5782 - val_loss: 1.2331 - val_accuracy: 0.5660\n",
            "Epoch 24/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.1841 - accuracy: 0.5816 - val_loss: 1.1876 - val_accuracy: 0.5905\n",
            "Epoch 25/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.1693 - accuracy: 0.5885 - val_loss: 1.1945 - val_accuracy: 0.5835\n",
            "Epoch 26/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.1566 - accuracy: 0.5941 - val_loss: 1.1769 - val_accuracy: 0.5860\n",
            "Epoch 27/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.1472 - accuracy: 0.5944 - val_loss: 1.1676 - val_accuracy: 0.5945\n",
            "Epoch 28/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.1343 - accuracy: 0.6012 - val_loss: 1.1390 - val_accuracy: 0.6025\n",
            "Epoch 29/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.1213 - accuracy: 0.6055 - val_loss: 1.1300 - val_accuracy: 0.6085\n",
            "Epoch 30/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.1123 - accuracy: 0.6103 - val_loss: 1.1269 - val_accuracy: 0.6080\n",
            "Epoch 31/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.0996 - accuracy: 0.6133 - val_loss: 1.1142 - val_accuracy: 0.6100\n",
            "Epoch 32/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.0900 - accuracy: 0.6169 - val_loss: 1.1007 - val_accuracy: 0.6115\n",
            "Epoch 33/80\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 1.0829 - accuracy: 0.6199 - val_loss: 1.1009 - val_accuracy: 0.6155\n",
            "Epoch 34/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.0716 - accuracy: 0.6254 - val_loss: 1.1166 - val_accuracy: 0.6070\n",
            "Epoch 35/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.0596 - accuracy: 0.6308 - val_loss: 1.0921 - val_accuracy: 0.6230\n",
            "Epoch 36/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.0514 - accuracy: 0.6329 - val_loss: 1.1025 - val_accuracy: 0.6075\n",
            "Epoch 37/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.0400 - accuracy: 0.6360 - val_loss: 1.0580 - val_accuracy: 0.6330\n",
            "Epoch 38/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.0336 - accuracy: 0.6382 - val_loss: 1.0578 - val_accuracy: 0.6305\n",
            "Epoch 39/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.0221 - accuracy: 0.6416 - val_loss: 1.0467 - val_accuracy: 0.6330\n",
            "Epoch 40/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.0142 - accuracy: 0.6471 - val_loss: 1.0475 - val_accuracy: 0.6280\n",
            "Epoch 41/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 1.0042 - accuracy: 0.6483 - val_loss: 1.0449 - val_accuracy: 0.6290\n",
            "Epoch 42/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.9973 - accuracy: 0.6507 - val_loss: 1.0331 - val_accuracy: 0.6420\n",
            "Epoch 43/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.9872 - accuracy: 0.6563 - val_loss: 1.0104 - val_accuracy: 0.6420\n",
            "Epoch 44/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.9764 - accuracy: 0.6585 - val_loss: 1.0105 - val_accuracy: 0.6355\n",
            "Epoch 45/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.9696 - accuracy: 0.6588 - val_loss: 0.9970 - val_accuracy: 0.6520\n",
            "Epoch 46/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.9592 - accuracy: 0.6654 - val_loss: 1.0270 - val_accuracy: 0.6360\n",
            "Epoch 47/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.9515 - accuracy: 0.6676 - val_loss: 0.9870 - val_accuracy: 0.6505\n",
            "Epoch 48/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.9462 - accuracy: 0.6692 - val_loss: 0.9914 - val_accuracy: 0.6470\n",
            "Epoch 49/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.9361 - accuracy: 0.6736 - val_loss: 1.0044 - val_accuracy: 0.6440\n",
            "Epoch 50/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.9309 - accuracy: 0.6753 - val_loss: 0.9707 - val_accuracy: 0.6460\n",
            "Epoch 51/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.9203 - accuracy: 0.6791 - val_loss: 0.9839 - val_accuracy: 0.6430\n",
            "Epoch 52/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.9126 - accuracy: 0.6833 - val_loss: 0.9800 - val_accuracy: 0.6545\n",
            "Epoch 53/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.9067 - accuracy: 0.6847 - val_loss: 0.9599 - val_accuracy: 0.6640\n",
            "Epoch 54/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.8977 - accuracy: 0.6895 - val_loss: 0.9453 - val_accuracy: 0.6585\n",
            "Epoch 55/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.8887 - accuracy: 0.6925 - val_loss: 0.9392 - val_accuracy: 0.6660\n",
            "Epoch 56/80\n",
            "391/391 [==============================] - 13s 33ms/step - loss: 0.8824 - accuracy: 0.6945 - val_loss: 0.9373 - val_accuracy: 0.6665\n",
            "Epoch 57/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.8729 - accuracy: 0.6963 - val_loss: 0.9572 - val_accuracy: 0.6675\n",
            "Epoch 58/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.8692 - accuracy: 0.6963 - val_loss: 0.9247 - val_accuracy: 0.6750\n",
            "Epoch 59/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.8603 - accuracy: 0.7014 - val_loss: 0.9292 - val_accuracy: 0.6670\n",
            "Epoch 60/80\n",
            "391/391 [==============================] - 13s 35ms/step - loss: 0.8526 - accuracy: 0.7053 - val_loss: 0.9229 - val_accuracy: 0.6765\n",
            "Epoch 61/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.8485 - accuracy: 0.7030 - val_loss: 0.9140 - val_accuracy: 0.6795\n",
            "Epoch 62/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.8367 - accuracy: 0.7089 - val_loss: 0.9094 - val_accuracy: 0.6805\n",
            "Epoch 63/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.8331 - accuracy: 0.7105 - val_loss: 0.9138 - val_accuracy: 0.6770\n",
            "Epoch 64/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.8232 - accuracy: 0.7129 - val_loss: 0.8876 - val_accuracy: 0.6875\n",
            "Epoch 65/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.8195 - accuracy: 0.7168 - val_loss: 0.8849 - val_accuracy: 0.6870\n",
            "Epoch 66/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.8124 - accuracy: 0.7179 - val_loss: 0.8894 - val_accuracy: 0.6890\n",
            "Epoch 67/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.8035 - accuracy: 0.7230 - val_loss: 0.8734 - val_accuracy: 0.6890\n",
            "Epoch 68/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.7979 - accuracy: 0.7232 - val_loss: 0.9124 - val_accuracy: 0.6755\n",
            "Epoch 69/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.7943 - accuracy: 0.7255 - val_loss: 0.8884 - val_accuracy: 0.6905\n",
            "Epoch 70/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.7836 - accuracy: 0.7279 - val_loss: 0.8848 - val_accuracy: 0.6925\n",
            "Epoch 71/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.7787 - accuracy: 0.7293 - val_loss: 0.8873 - val_accuracy: 0.6900\n",
            "Epoch 72/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.7720 - accuracy: 0.7331 - val_loss: 0.8560 - val_accuracy: 0.7015\n",
            "Epoch 73/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.7670 - accuracy: 0.7328 - val_loss: 0.8569 - val_accuracy: 0.6970\n",
            "Epoch 74/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.7581 - accuracy: 0.7370 - val_loss: 0.8523 - val_accuracy: 0.6975\n",
            "Epoch 75/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.7524 - accuracy: 0.7373 - val_loss: 0.8483 - val_accuracy: 0.7005\n",
            "Epoch 76/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.7487 - accuracy: 0.7412 - val_loss: 0.8588 - val_accuracy: 0.6925\n",
            "Epoch 77/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.7429 - accuracy: 0.7414 - val_loss: 0.8316 - val_accuracy: 0.7105\n",
            "Epoch 78/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.7362 - accuracy: 0.7447 - val_loss: 0.8401 - val_accuracy: 0.7035\n",
            "Epoch 79/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.7310 - accuracy: 0.7459 - val_loss: 0.8429 - val_accuracy: 0.6970\n",
            "Epoch 80/80\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.7240 - accuracy: 0.7495 - val_loss: 0.8294 - val_accuracy: 0.7105\n",
            "Baseline 정확률은 72.13000059127808\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 1, 1, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1000)              2049000   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 500)               500500    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                5010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,142,222\n",
            "Trainable params: 26,089,102\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "391/391 [==============================] - 69s 155ms/step - loss: 1.7848 - accuracy: 0.3837 - val_loss: 149.5305 - val_accuracy: 0.1040\n",
            "Epoch 2/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 1.1112 - accuracy: 0.6125 - val_loss: 3.1296 - val_accuracy: 0.1870\n",
            "Epoch 3/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.8376 - accuracy: 0.7092 - val_loss: 1.1018 - val_accuracy: 0.6225\n",
            "Epoch 4/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.6485 - accuracy: 0.7769 - val_loss: 1.0323 - val_accuracy: 0.6655\n",
            "Epoch 5/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.4944 - accuracy: 0.8327 - val_loss: 1.0353 - val_accuracy: 0.6775\n",
            "Epoch 6/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.3757 - accuracy: 0.8755 - val_loss: 1.0584 - val_accuracy: 0.6760\n",
            "Epoch 7/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.2729 - accuracy: 0.9129 - val_loss: 1.0995 - val_accuracy: 0.6925\n",
            "Epoch 8/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.2006 - accuracy: 0.9392 - val_loss: 1.1551 - val_accuracy: 0.6955\n",
            "Epoch 9/80\n",
            "391/391 [==============================] - 58s 147ms/step - loss: 0.1504 - accuracy: 0.9542 - val_loss: 1.1760 - val_accuracy: 0.6955\n",
            "Epoch 10/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.1122 - accuracy: 0.9672 - val_loss: 1.2753 - val_accuracy: 0.6925\n",
            "Epoch 11/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0872 - accuracy: 0.9748 - val_loss: 1.2866 - val_accuracy: 0.6980\n",
            "Epoch 12/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0710 - accuracy: 0.9795 - val_loss: 1.3711 - val_accuracy: 0.6990\n",
            "Epoch 13/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0601 - accuracy: 0.9835 - val_loss: 1.4015 - val_accuracy: 0.7025\n",
            "Epoch 14/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0551 - accuracy: 0.9841 - val_loss: 1.4633 - val_accuracy: 0.7100\n",
            "Epoch 15/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0508 - accuracy: 0.9845 - val_loss: 1.5028 - val_accuracy: 0.7115\n",
            "Epoch 16/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0460 - accuracy: 0.9859 - val_loss: 1.4925 - val_accuracy: 0.7070\n",
            "Epoch 17/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0426 - accuracy: 0.9869 - val_loss: 1.5557 - val_accuracy: 0.7055\n",
            "Epoch 18/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0393 - accuracy: 0.9875 - val_loss: 1.5652 - val_accuracy: 0.7115\n",
            "Epoch 19/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0360 - accuracy: 0.9887 - val_loss: 1.6004 - val_accuracy: 0.7125\n",
            "Epoch 20/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0343 - accuracy: 0.9890 - val_loss: 1.5923 - val_accuracy: 0.7130\n",
            "Epoch 21/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0324 - accuracy: 0.9899 - val_loss: 1.6333 - val_accuracy: 0.7110\n",
            "Epoch 22/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0288 - accuracy: 0.9908 - val_loss: 1.6419 - val_accuracy: 0.7180\n",
            "Epoch 23/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0319 - accuracy: 0.9897 - val_loss: 1.6003 - val_accuracy: 0.7235\n",
            "Epoch 24/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0299 - accuracy: 0.9905 - val_loss: 1.6775 - val_accuracy: 0.7155\n",
            "Epoch 25/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0258 - accuracy: 0.9918 - val_loss: 1.6566 - val_accuracy: 0.7235\n",
            "Epoch 26/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0259 - accuracy: 0.9915 - val_loss: 1.7355 - val_accuracy: 0.7155\n",
            "Epoch 27/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0244 - accuracy: 0.9922 - val_loss: 1.7054 - val_accuracy: 0.7195\n",
            "Epoch 28/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0255 - accuracy: 0.9922 - val_loss: 1.6720 - val_accuracy: 0.7245\n",
            "Epoch 29/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0241 - accuracy: 0.9928 - val_loss: 1.6663 - val_accuracy: 0.7320\n",
            "Epoch 30/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0223 - accuracy: 0.9930 - val_loss: 1.6982 - val_accuracy: 0.7300\n",
            "Epoch 31/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 1.7619 - val_accuracy: 0.7225\n",
            "Epoch 32/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 1.7170 - val_accuracy: 0.7355\n",
            "Epoch 33/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0216 - accuracy: 0.9934 - val_loss: 1.7191 - val_accuracy: 0.7220\n",
            "Epoch 34/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 1.6611 - val_accuracy: 0.7335\n",
            "Epoch 35/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 1.7437 - val_accuracy: 0.7340\n",
            "Epoch 36/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 1.7327 - val_accuracy: 0.7305\n",
            "Epoch 37/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0219 - accuracy: 0.9931 - val_loss: 1.7225 - val_accuracy: 0.7300\n",
            "Epoch 38/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 1.6676 - val_accuracy: 0.7315\n",
            "Epoch 39/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0185 - accuracy: 0.9944 - val_loss: 1.7142 - val_accuracy: 0.7330\n",
            "Epoch 40/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0183 - accuracy: 0.9939 - val_loss: 1.7317 - val_accuracy: 0.7360\n",
            "Epoch 41/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 1.7306 - val_accuracy: 0.7365\n",
            "Epoch 42/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 1.7545 - val_accuracy: 0.7335\n",
            "Epoch 43/80\n",
            "391/391 [==============================] - 58s 148ms/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 1.7343 - val_accuracy: 0.7390\n",
            "Epoch 44/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 1.8194 - val_accuracy: 0.7285\n",
            "Epoch 45/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 1.7989 - val_accuracy: 0.7445\n",
            "Epoch 46/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 1.8180 - val_accuracy: 0.7305\n",
            "Epoch 47/80\n",
            "391/391 [==============================] - 58s 148ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 1.7726 - val_accuracy: 0.7400\n",
            "Epoch 48/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 1.7907 - val_accuracy: 0.7305\n",
            "Epoch 49/80\n",
            "391/391 [==============================] - 58s 147ms/step - loss: 0.0149 - accuracy: 0.9948 - val_loss: 1.8027 - val_accuracy: 0.7340\n",
            "Epoch 50/80\n",
            "391/391 [==============================] - 58s 147ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 1.8205 - val_accuracy: 0.7455\n",
            "Epoch 51/80\n",
            "391/391 [==============================] - 58s 147ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 1.8211 - val_accuracy: 0.7405\n",
            "Epoch 52/80\n",
            "391/391 [==============================] - 58s 147ms/step - loss: 0.0130 - accuracy: 0.9962 - val_loss: 1.8781 - val_accuracy: 0.7295\n",
            "Epoch 53/80\n",
            "391/391 [==============================] - 58s 147ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 1.8479 - val_accuracy: 0.7360\n",
            "Epoch 54/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 1.8661 - val_accuracy: 0.7340\n",
            "Epoch 55/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 1.8137 - val_accuracy: 0.7340\n",
            "Epoch 56/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 1.8098 - val_accuracy: 0.7345\n",
            "Epoch 57/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 1.7973 - val_accuracy: 0.7400\n",
            "Epoch 58/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 1.8379 - val_accuracy: 0.7435\n",
            "Epoch 59/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 1.8219 - val_accuracy: 0.7420\n",
            "Epoch 60/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 1.8390 - val_accuracy: 0.7400\n",
            "Epoch 61/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 1.7788 - val_accuracy: 0.7485\n",
            "Epoch 62/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 1.8134 - val_accuracy: 0.7405\n",
            "Epoch 63/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 1.8250 - val_accuracy: 0.7355\n",
            "Epoch 64/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 1.8513 - val_accuracy: 0.7440\n",
            "Epoch 65/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 1.8322 - val_accuracy: 0.7370\n",
            "Epoch 66/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 1.7955 - val_accuracy: 0.7470\n",
            "Epoch 67/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 1.8010 - val_accuracy: 0.7435\n",
            "Epoch 68/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 1.8322 - val_accuracy: 0.7415\n",
            "Epoch 69/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 1.8358 - val_accuracy: 0.7445\n",
            "Epoch 70/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 1.7976 - val_accuracy: 0.7510\n",
            "Epoch 71/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 1.8184 - val_accuracy: 0.7525\n",
            "Epoch 72/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 1.8432 - val_accuracy: 0.7555\n",
            "Epoch 73/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 1.7654 - val_accuracy: 0.7630\n",
            "Epoch 74/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 1.7805 - val_accuracy: 0.7495\n",
            "Epoch 75/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 1.7902 - val_accuracy: 0.7600\n",
            "Epoch 76/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 1.8283 - val_accuracy: 0.7580\n",
            "Epoch 77/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 1.8132 - val_accuracy: 0.7555\n",
            "Epoch 78/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 1.7885 - val_accuracy: 0.7480\n",
            "Epoch 79/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 1.8267 - val_accuracy: 0.7520\n",
            "Epoch 80/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 1.8777 - val_accuracy: 0.7600\n",
            "Baseline vs yours:  72.13000059127808 76.02999806404114\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"과제5 CNN기반 영상분류문제\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1Py2GvZc1GwqNbrR4fuQrHFy6zBEdF1xF\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten,Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
        "x_train=x_train.astype(np.float32)/255.0\n",
        "y_train=tf.keras.utils.to_categorical(y_train,10)\n",
        "\n",
        "x_test=x_test.astype(np.float32)/255.0\n",
        "y_test=tf.keras.utils.to_categorical(y_test,10)\n",
        "\n",
        "#x_train, _, y_train,_ = train_test_split(x_train, y_train, test_size=0.5, random_state=42)\n",
        "x_val, _, y_val,_ = train_test_split(x_test, y_test, test_size=0.8, random_state=42)\n",
        "\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "#동일조건 유지해야 하는 변수(두 모델 모두 동일하게 적용해야 함)\n",
        "g_epoch = 80\n",
        "g_batch = 128\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"reduced train/val size:\", len(x_train), len(x_val), \"input shape:\", input_shape)\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "\n",
        "tf.__version__\n",
        "\n",
        "from tensorflow.keras.layers import MaxPooling2D, Dropout, Conv2D\n",
        "\n",
        "cnn=Sequential()\n",
        "cnn.add(Conv2D(64,(3,3),activation='relu',input_shape=(32,32,3)))\n",
        "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnn.add(Dropout(0.25))\n",
        "cnn.add(Conv2D(128,(3,3),activation='relu', padding='same'))\n",
        "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnn.add(Dropout(0.25))\n",
        "cnn.add(Conv2D(256,(3,3),activation='relu', padding='same'))\n",
        "cnn.add(Conv2D(256,(3,3),activation='relu', padding='same'))\n",
        "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(1000,activation='relu'))\n",
        "cnn.add(Dropout(0.5))\n",
        "cnn.add(Dense(10,activation='softmax'))\n",
        "\n",
        "cnn.compile(loss='categorical_crossentropy',optimizer=Adam(0.00002),metrics=['accuracy'])\n",
        "cnn.summary()\n",
        "\n",
        "hist=cnn.fit(x_train, y_train, batch_size=g_batch, epochs=g_epoch,\n",
        "             validation_data=(x_val,y_val), verbose=1)\n",
        "\n",
        "g_org_res=cnn.evaluate(x_test,y_test,verbose=0)\n",
        "print(\"Baseline 정확률은\",g_org_res[1]*100)\n",
        "\n",
        "no_class = 10\n",
        "\n",
        "# for transfer learning only\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# for transfer learning only\n",
        "transfermodel = ResNet50(weights='imagenet',include_top=False,\n",
        "                    input_shape=input_shape)\n",
        "#base_model.trainable=False     # it's up to you\n",
        "\n",
        "# your model architecture\n",
        "model=Sequential()\n",
        "model.add(transfermodel)    # for transfer learning only\n",
        "model.add(Flatten())        # for transfer learning only\n",
        "model.add(Dense(1000,activation='relu'))\n",
        "model.add(Dense(500,activation='relu'))    #layer 하나 더 추가\n",
        "model.add(Dense(no_class, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(0.00002),metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "hist=model.fit(x_train, y_train, batch_size=g_batch, epochs=g_epoch,\n",
        "             validation_data=(x_val,y_val), verbose=1)\n",
        "\n",
        "yours=model.evaluate(x_test,y_test,verbose=0)\n",
        "print(\"Baseline vs yours: \",g_org_res[1]*100, yours[1]*100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4qpiI2-I3Qq7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}